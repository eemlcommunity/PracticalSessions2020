{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet18_cifar10_adversarial.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGuivbg9OJ-w",
        "colab_type": "text"
      },
      "source": [
        "# Part 2: Generating adversarial examples: first demonstrated in [Intriguing properties of neural networks](https://arxiv.org/pdf/1312.6199.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUhxehxYHuuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Setup and imports\n",
        "\n",
        "from typing import Mapping, Tuple, Optional, Sequence, Union\n",
        "\n",
        "from absl import app\n",
        "from absl import flags\n",
        "from absl import logging\n",
        "\n",
        "# We will use haiku on top of jax; it is not included by default, so let's install it  \n",
        "!pip install -q dm-haiku\n",
        "import haiku as hk\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp  # equivalent on numpy on GPU and TPU\n",
        "import numpy as np  # original numpy\n",
        "\n",
        "# Dataset library\n",
        "import tensorflow.compat.v2 as tf\n",
        "#import tensorflow_datasets as tfds\n",
        "\n",
        "# Plotting library.\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from urllib.request import urlopen\n",
        "import pickle\n",
        "\n",
        "# Don't forget to select GPU runtime environment in Runtime -> Change runtime type\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "random_seed = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maQt-JG5HChv",
        "colab_type": "text"
      },
      "source": [
        "### Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBSFLp_VNsaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset constants for cifar10 dataset:\n",
        "# it contains low-res natural images (32x32x3) belonging to 10 classes. \n",
        "num_classes = 10\n",
        "\n",
        "class_dict = [u'airplane', u'automobile', u'bird', u'cat', u'deer', u'dog', u'frog', u'horse', u'ship', u'truck']\n",
        "\n",
        "def display_logits(logits: jnp.ndarray):\n",
        "  softmax = np.exp(logits)/np.sum(np.exp(logits), axis=1, keepdims=True)\n",
        "  plt.bar(range(len(class_dict)), softmax[0])\n",
        "  plt.xticks(range(len(class_dict)), class_dict, rotation='vertical')\n",
        "  plt.show()\n",
        "  max_prob = float(np.max(softmax))\n",
        "  max_cls = class_dict[np.argmax(softmax)]\n",
        "  print(\"{:.3f}% confident that this is class {}.\".format(max_prob*100,max_cls))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI1xFR8eGr5p",
        "colab_type": "text"
      },
      "source": [
        "### Load the image to attack, and specify the target class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPD4on8RD2Z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_url = \"https://github.com/eemlcommunity/PracticalSessions2020/raw/master/assets/airplane.pkl\" #@param\n",
        "\n",
        "with urlopen(image_url) as f:\n",
        "  image = pickle.load(f)\n",
        "\n",
        "# Note: this image has already been preprocessed for the neural net.\n",
        "plt.imshow((image+1.)/2.)\n",
        "\n",
        "# the class that we'll trick the classifier into outputting for this image.\n",
        "target_class = 'horse' #@param"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu3_qgA-7N0G",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Define the model: Resnet18\n",
        "def check_length(length, value, name):\n",
        "  if len(value) != length:\n",
        "    raise ValueError(f\"`{name}` must be of length 4 not {len(value)}\")\n",
        "\n",
        "class BlockV2(hk.Module):\n",
        "  \"\"\"ResNet V2 block with optional bottleneck.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      channels: int,\n",
        "      stride: Union[int, Sequence[int]],\n",
        "      use_projection: bool,\n",
        "      bn_config: Mapping[str, float],\n",
        "      bottleneck: bool,\n",
        "      name: Optional[str] = None,\n",
        "  ):\n",
        "    super().__init__(name=name)\n",
        "    self.use_projection = use_projection\n",
        "\n",
        "    # define batch norm parameters\n",
        "    bn_config = dict(bn_config)\n",
        "    bn_config.setdefault(\"create_scale\", True)\n",
        "    bn_config.setdefault(\"create_offset\", True)\n",
        "\n",
        "    if self.use_projection:\n",
        "      self.proj_conv = hk.Conv2D(\n",
        "          output_channels=channels,\n",
        "          kernel_shape=1,\n",
        "          stride=stride,\n",
        "          with_bias=False,\n",
        "          padding=\"SAME\",\n",
        "          name=\"shortcut_conv\")\n",
        "\n",
        "    channel_div = 4 if bottleneck else 1\n",
        "    conv_0 = hk.Conv2D(\n",
        "        output_channels=channels // channel_div,\n",
        "        kernel_shape=1 if bottleneck else 3,\n",
        "        stride=1,\n",
        "        with_bias=False,\n",
        "        padding=\"SAME\",\n",
        "        name=\"conv_0\")\n",
        "\n",
        "    bn_0 = hk.BatchNorm(name=\"batchnorm_0\", **bn_config)\n",
        "\n",
        "    conv_1 = hk.Conv2D(\n",
        "        output_channels=channels // channel_div,\n",
        "        kernel_shape=3,\n",
        "        stride=stride,\n",
        "        with_bias=False,\n",
        "        padding=\"SAME\",\n",
        "        name=\"conv_1\")\n",
        "\n",
        "    bn_1 = hk.BatchNorm(name=\"batchnorm_1\", **bn_config)\n",
        "    layers = ((conv_0, bn_0), (conv_1, bn_1))\n",
        "\n",
        "    if bottleneck:\n",
        "      conv_2 = hk.Conv2D(\n",
        "          output_channels=channels,\n",
        "          kernel_shape=1,\n",
        "          stride=1,\n",
        "          with_bias=False,\n",
        "          padding=\"SAME\",\n",
        "          name=\"conv_2\")\n",
        "\n",
        "      bn_2 = hk.BatchNorm(name=\"batchnorm_2\", **bn_config)\n",
        "      layers = layers + ((conv_2, bn_2),)\n",
        "\n",
        "    self.layers = layers\n",
        "\n",
        "  def __call__(self, inputs, is_training, test_local_stats):\n",
        "    x = shortcut = inputs\n",
        "\n",
        "    for i, (conv_i, bn_i) in enumerate(self.layers):\n",
        "      x = bn_i(x, is_training, test_local_stats)\n",
        "      x = jax.nn.relu(x)\n",
        "      if i == 0 and self.use_projection:\n",
        "        shortcut = self.proj_conv(x)\n",
        "      x = conv_i(x)\n",
        "\n",
        "    return x + shortcut\n",
        "\n",
        "\n",
        "class BlockGroup(hk.Module):\n",
        "  \"\"\"Group of blocks for ResNet implementation.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      channels: int,\n",
        "      num_blocks: int,\n",
        "      stride: Union[int, Sequence[int]],\n",
        "      bn_config: Mapping[str, float],\n",
        "      bottleneck: bool,\n",
        "      use_projection: bool,\n",
        "      name: Optional[str] = None,\n",
        "  ):\n",
        "    super().__init__(name=name)\n",
        "\n",
        "    self.blocks = []\n",
        "    for i in range(num_blocks):\n",
        "      self.blocks.append(\n",
        "          BlockV2(channels=channels,\n",
        "                  stride=(1 if i else stride),\n",
        "                  use_projection=(i == 0 and use_projection),\n",
        "                  bottleneck=bottleneck,\n",
        "                  bn_config=bn_config,\n",
        "                  name=\"block_%d\" % (i)))\n",
        "\n",
        "  def __call__(self, inputs, is_training, test_local_stats):\n",
        "    out = inputs\n",
        "    for block in self.blocks:\n",
        "      out = block(out, is_training, test_local_stats)\n",
        "    return out\n",
        "\n",
        "\n",
        "class ResNet(hk.Module):\n",
        "  \"\"\"ResNet model.\"\"\"\n",
        "\n",
        "  BlockGroup = BlockGroup  # pylint: disable=invalid-name\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      blocks_per_group: Sequence[int],\n",
        "      num_classes: int,\n",
        "      bn_config: Optional[Mapping[str, float]] = None,\n",
        "      bottleneck: bool = True,\n",
        "      channels_per_group: Sequence[int] = (256, 512, 1024, 2048),\n",
        "      use_projection: Sequence[bool] = (True, True, True, True),\n",
        "      name: Optional[str] = None,\n",
        "  ):\n",
        "    \"\"\"Constructs a ResNet model.\n",
        "    Args:\n",
        "      blocks_per_group: A sequence of length 4 that indicates the number of\n",
        "        blocks created in each group.\n",
        "      num_classes: The number of classes to classify the inputs into.\n",
        "      bn_config: A dictionary of two elements, `decay_rate` and `eps` to be\n",
        "        passed on to the `BatchNorm` layers. By default the `decay_rate` is\n",
        "        `0.9` and `eps` is `1e-5`.\n",
        "       bottleneck: Whether the block should bottleneck or not. Defaults to True.\n",
        "      channels_per_group: A sequence of length 4 that indicates the number\n",
        "        of channels used for each block in each group.\n",
        "      use_projection: A sequence of length 4 that indicates whether each\n",
        "        residual block should use projection.\n",
        "      name: Name of the module.\n",
        "    \"\"\"\n",
        "    super().__init__(name=name)\n",
        "    bn_config = dict(bn_config or {})\n",
        "    bn_config.setdefault(\"decay_rate\", 0.9)\n",
        "    bn_config.setdefault(\"eps\", 1e-5)\n",
        "    bn_config.setdefault(\"create_scale\", True)\n",
        "    bn_config.setdefault(\"create_offset\", True)\n",
        "\n",
        "    # Number of blocks in each group for ResNet.\n",
        "    check_length(4, blocks_per_group, \"blocks_per_group\")\n",
        "    check_length(4, channels_per_group, \"channels_per_group\")\n",
        "\n",
        "    self.initial_conv = hk.Conv2D(\n",
        "        output_channels=64,\n",
        "        kernel_shape=7,\n",
        "        stride=2,\n",
        "        with_bias=False,\n",
        "        padding=\"SAME\",\n",
        "        name=\"initial_conv\")\n",
        "\n",
        "    self.block_groups = []\n",
        "    strides = (1, 2, 2, 2)\n",
        "    for i in range(4):\n",
        "      self.block_groups.append(\n",
        "          BlockGroup(channels=channels_per_group[i],\n",
        "                     num_blocks=blocks_per_group[i],\n",
        "                     stride=strides[i],\n",
        "                     bn_config=bn_config,\n",
        "                     bottleneck=bottleneck,\n",
        "                     use_projection=use_projection[i],\n",
        "                     name=\"block_group_%d\" % (i)))\n",
        "\n",
        "    self.final_batchnorm = hk.BatchNorm(name=\"final_batchnorm\", **bn_config)\n",
        "    self.logits = hk.Linear(num_classes, w_init=jnp.zeros, name=\"logits\")\n",
        "\n",
        "  def __call__(self, inputs, is_training, test_local_stats=False):\n",
        "    out = inputs\n",
        "    out = self.initial_conv(out)\n",
        "\n",
        "    out = hk.max_pool(out,\n",
        "                      window_shape=(1, 3, 3, 1),\n",
        "                      strides=(1, 2, 2, 1),\n",
        "                      padding=\"SAME\")\n",
        "\n",
        "    for block_group in self.block_groups:\n",
        "      out = block_group(out, is_training, test_local_stats)\n",
        "\n",
        "    out = self.final_batchnorm(out, is_training, test_local_stats)\n",
        "    out = jax.nn.relu(out)\n",
        "    out = jnp.mean(out, axis=[1, 2])\n",
        "    return self.logits(out)\n",
        "\n",
        "\n",
        "class ResNet18(ResNet):\n",
        "  \"\"\"ResNet18.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               num_classes: int,\n",
        "               bn_config: Optional[Mapping[str, float]] = None,\n",
        "               name: Optional[str] = None):\n",
        "    \"\"\"Constructs a ResNet model.\n",
        "    Args:\n",
        "      num_classes: The number of classes to classify the inputs into.\n",
        "      bn_config: A dictionary of two elements, `decay_rate` and `eps` to be\n",
        "        passed on to the `BatchNorm` layers.\n",
        "      name: Name of the module.\n",
        "    \"\"\"\n",
        "    super().__init__(blocks_per_group=(2, 2, 2, 2),\n",
        "                     num_classes=num_classes,\n",
        "                     bn_config=bn_config,\n",
        "                     bottleneck=False,\n",
        "                     channels_per_group=(64, 128, 256, 512),\n",
        "                     use_projection=(False, True, True, True),\n",
        "                     name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH1DDv9fLq2G",
        "colab_type": "text"
      },
      "source": [
        "### Create the forward pass of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJzMPIQpKwBQ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "def net_fn(\n",
        "    batch: jnp.array,\n",
        "    is_training: bool,\n",
        ") -> jnp.ndarray:\n",
        "  \"\"\"Forward pass of the resnet.\"\"\"\n",
        "  model = ResNet18(num_classes, bn_config={'decay_rate': 1.0})\n",
        "  return model(batch, is_training=is_training)\n",
        "\n",
        "# Transform the forward function into a pair of pure functions.\n",
        "# We use transform with state because we need to keep the state of the network,\n",
        "# e.g. for batch norm statistics.\n",
        "net = hk.transform_with_state(net_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gANDnVXpQhW6",
        "colab_type": "text"
      },
      "source": [
        "### Load the network parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcnhc-a0KalI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These pickle files were created by pickling the 'params' and 'state' from the\n",
        "# previous tutorial.\n",
        "param_pkl = \"https://github.com/eemlcommunity/PracticalSessions2020/raw/master/assets/checkpoint_resnet18_cifar_params.pkl\"\n",
        "state_pkl = \"https://github.com/eemlcommunity/PracticalSessions2020/raw/master/assets/checkpoint_resnet18_cifar_state.pkl\"\n",
        "\n",
        "with urlopen(param_pkl) as f:\n",
        "  params = pickle.load(f)\n",
        "\n",
        "with urlopen(state_pkl) as f:\n",
        "  state = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iswLov_IROxH",
        "colab_type": "text"
      },
      "source": [
        "### Run the network on the image that we'll attack.  Unsurprisingly, the network is confident it's an airplane."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LGfArpnKsi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: the None is for the random number generator; this network never uses it.\n",
        "logits, _ = net.apply(params, state, None, image[None,:,:,:], is_training=False)\n",
        "display_logits(logits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxcy4MB-SHnG",
        "colab_type": "text"
      },
      "source": [
        "###Next define the loss function for an adversarial perturbation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWaaqVGbCkvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = 1.0 #@param\n",
        "\n",
        "# A useful utility.\n",
        "def softmax_cross_entropy(\n",
        "    *,\n",
        "    logits: jnp.ndarray,\n",
        "    labels: jnp.ndarray,\n",
        ") -> jnp.ndarray:\n",
        "  return -jnp.sum(labels * jax.nn.log_softmax(logits))\n",
        "\n",
        "# Define a function which applies an image perturbation. \"noise\" is the array \n",
        "# that we'll be optimizing to attack the network; its shape is \n",
        "# [height, width, 3]. \"image\" is the image we'll be attacking, also of shape\n",
        "# [height, width, 3]. Output an altered image. Note: the result should still \n",
        "# be a valid image (i.e. constrained to be in the range [-1, 1], no matter what\n",
        "# the noise is).\n",
        "def apply_perturbation(\n",
        "    noise: jnp.ndarray,\n",
        "    image: jnp.ndarray,\n",
        ") -> jnp.ndarray:\n",
        "  ######################\n",
        "  ### YOUR CODE HERE ###\n",
        "  ######################\n",
        "  return jnp.maximum(-1.0, jnp.minimum(1.0, image + noise))\n",
        "\n",
        "# Define a loss function on the noise. Following the paper, the loss should be\n",
        "# the cross entropy with the target class, plus alpha (defined above) times the \n",
        "# sum-of-squares for the noise. \n",
        "# \n",
        "# Define the loss in code.  Use 1.0 for alpha to start with.\n",
        "def loss_fn(\n",
        "    noise: jnp.ndarray,\n",
        "    image: jnp.ndarray,\n",
        ") -> jnp.ndarray:\n",
        "  \"\"\"Computes the initial network state.\"\"\"\n",
        "  perturbed = apply_perturbation(noise, image)\n",
        "  perturbed = perturbed[None,:,:,:]\n",
        "  logits, _ = net.apply(params, state, None, perturbed, is_training=False)\n",
        "\n",
        "  ######################\n",
        "  ### YOUR CODE HERE ###\n",
        "  ######################\n",
        "  labels = (np.array(class_dict) == target_class).astype(np.float32)\n",
        "  loss = softmax_cross_entropy(logits=logits, labels=labels)\n",
        "  loss += alpha * jnp.sum(jnp.square(noise))\n",
        "  return loss\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCWzHnnlgc77",
        "colab_type": "text"
      },
      "source": [
        "### The training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKT2eDxGSFN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise_val = jnp.zeros_like(image)\n",
        "\n",
        "grad_fn = jax.grad(loss_fn)\n",
        "\n",
        "# Next write a training loop: apply the grad_fn to get gradients for noise_val,\n",
        "# and then update noise_val with stochastic gradient descent. Print out the \n",
        "# loss value at every iteration, and try to get the loss below 1.43.  Don't\n",
        "# worry about optimizing it to be fast or using fancy optimizers (unless you \n",
        "# want to). With ordinary SGD and an appropriate learning rate schedule, it can\n",
        "# be done in 50 update steps.\n",
        "\n",
        "######################\n",
        "### YOUR CODE HERE ###\n",
        "######################\n",
        "for i in range(50):\n",
        "  print(loss_fn(noise_val, image))\n",
        "  grad = grad_fn(noise_val, image)\n",
        "  noise_val -= grad * (.005 if i > 20 else .05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xq5f2BYgh1s",
        "colab_type": "text"
      },
      "source": [
        "### Plot the final image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys8skFynK6Z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.imshow((apply_perturbation(noise_val, image) + 1.)/2.)\n",
        "plt.show()\n",
        "plt.imshow((noise_val+1.)/2.)\n",
        "plt.show()\n",
        "plt.imshow((noise_val+.1)/0.2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h420YaOiXID",
        "colab_type": "text"
      },
      "source": [
        "### Finally, classify the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG_RUBs-JY5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If all went well, you should see about a 90% confidence that the airplane is\n",
        "# a horse if alpha = 1.0.  \n",
        "\n",
        "perturbed = apply_perturbation(noise_val, image)[None,:,:,:]\n",
        "logits, _ = net.apply(params, state, None, perturbed, is_training=False)\n",
        "display_logits(logits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-ye0grdldzl",
        "colab_type": "text"
      },
      "source": [
        "### Boosting the Confidence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkQVyJLAldCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next, go back to previous cells, and adjust alpha (and potentially the\n",
        "# learning rate schedule too) so that the confidence for horse is 99%, but the\n",
        "# image still looks as much like the original airplane as possible.  How \n",
        "# confident can you make the classifier while the image still looks like an \n",
        "# airplane?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNP8O5gppNfL",
        "colab_type": "text"
      },
      "source": [
        "### Generality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlpmtKgaoeAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This procedure almost always works.  To demonstrate, here's an automobile\n",
        "# from the eval set.  Try turning it into a dog or any other category you like.\n",
        "# Do some categories require larger perturbations than others?\n",
        "\n",
        "image_url = \"https://github.com/eemlcommunity/PracticalSessions2020/raw/master/assets/car.pkl\" #@param\n",
        "\n",
        "with urlopen(image_url) as f:\n",
        "  image = pickle.load(f)\n",
        "\n",
        "# Note: this image has already been preprocessed for the neural net.\n",
        "plt.imshow((image+1.)/2.);\n",
        "\n",
        "target_class = 'dog' #@param"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}